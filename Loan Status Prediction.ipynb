{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np                     # For mathematical calculations\n",
    "import seaborn as sns                  # For data visualization\n",
    "import matplotlib.pyplot as plt        # For plotting graphs\n",
    "%matplotlib inline\n",
    "import warnings                        # To ignore any warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test=pd.read_csv(r\"G:\\Loan Prediction Data\\data.csv\")\n",
    "train= pd.read_csv(r\"G:\\Loan Prediction Data\\datatest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LP001011</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5417</td>\n",
       "      <td>4196.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LP001013</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2333</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LP001014</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3+</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3036</td>\n",
       "      <td>2504.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LP001018</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4006</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LP001020</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>12841</td>\n",
       "      <td>10968.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LP001024</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3200</td>\n",
       "      <td>700.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LP001027</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2500</td>\n",
       "      <td>1840.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LP001028</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3073</td>\n",
       "      <td>8106.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LP001029</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>1853</td>\n",
       "      <td>2840.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LP001030</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>1299</td>\n",
       "      <td>1086.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LP001032</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LP001034</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LP001036</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LP001038</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LP001041</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2600</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LP001043</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>7660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LP001046</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5955</td>\n",
       "      <td>5625.0</td>\n",
       "      <td>315.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LP001047</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2600</td>\n",
       "      <td>1911.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LP001050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3365</td>\n",
       "      <td>1917.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LP001052</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3717</td>\n",
       "      <td>2925.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LP001066</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LP001068</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2799</td>\n",
       "      <td>2253.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LP001073</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4226</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LP001086</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>1442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LP001087</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3750</td>\n",
       "      <td>2083.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>LP001243</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3208</td>\n",
       "      <td>3066.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>LP001245</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1875</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>LP001248</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>LP001250</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3+</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>LP001253</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3+</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5266</td>\n",
       "      <td>1774.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>LP001255</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>LP001256</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3750</td>\n",
       "      <td>4750.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>LP001259</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1000</td>\n",
       "      <td>3022.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>LP001263</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3+</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3167</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>LP001264</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3+</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3333</td>\n",
       "      <td>2166.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>LP001265</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>LP001266</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>LP001267</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>1378</td>\n",
       "      <td>1881.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>LP001273</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>LP001275</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>LP001279</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2366</td>\n",
       "      <td>2531.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>LP001280</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3333</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>LP001282</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2500</td>\n",
       "      <td>2118.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>LP001289</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>8566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>LP001310</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5695</td>\n",
       "      <td>4167.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>LP001316</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2958</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>LP001318</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6250</td>\n",
       "      <td>5654.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>LP001319</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3273</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>LP001322</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>LP001325</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>3620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>LP001326</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Urban</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>LP001327</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2484</td>\n",
       "      <td>2302.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>LP001333</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>1977</td>\n",
       "      <td>997.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>LP001334</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>LP001343</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>1759</td>\n",
       "      <td>3541.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Loan_ID  Gender Married Dependents     Education Self_Employed  \\\n",
       "0   LP001002    Male      No          0      Graduate            No   \n",
       "1   LP001003    Male     Yes          1      Graduate            No   \n",
       "2   LP001005    Male     Yes          0      Graduate           Yes   \n",
       "3   LP001006    Male     Yes          0  Not Graduate            No   \n",
       "4   LP001008    Male      No          0      Graduate            No   \n",
       "5   LP001011    Male     Yes          2      Graduate           Yes   \n",
       "6   LP001013    Male     Yes          0  Not Graduate            No   \n",
       "7   LP001014    Male     Yes         3+      Graduate            No   \n",
       "8   LP001018    Male     Yes          2      Graduate            No   \n",
       "9   LP001020    Male     Yes          1      Graduate            No   \n",
       "10  LP001024    Male     Yes          2      Graduate            No   \n",
       "11  LP001027    Male     Yes          2      Graduate           NaN   \n",
       "12  LP001028    Male     Yes          2      Graduate            No   \n",
       "13  LP001029    Male      No          0      Graduate            No   \n",
       "14  LP001030    Male     Yes          2      Graduate            No   \n",
       "15  LP001032    Male      No          0      Graduate            No   \n",
       "16  LP001034    Male      No          1  Not Graduate            No   \n",
       "17  LP001036  Female      No          0      Graduate            No   \n",
       "18  LP001038    Male     Yes          0  Not Graduate            No   \n",
       "19  LP001041    Male     Yes          0      Graduate           NaN   \n",
       "20  LP001043    Male     Yes          0  Not Graduate            No   \n",
       "21  LP001046    Male     Yes          1      Graduate            No   \n",
       "22  LP001047    Male     Yes          0  Not Graduate            No   \n",
       "23  LP001050     NaN     Yes          2  Not Graduate            No   \n",
       "24  LP001052    Male     Yes          1      Graduate           NaN   \n",
       "25  LP001066    Male     Yes          0      Graduate           Yes   \n",
       "26  LP001068    Male     Yes          0      Graduate            No   \n",
       "27  LP001073    Male     Yes          2  Not Graduate            No   \n",
       "28  LP001086    Male      No          0  Not Graduate            No   \n",
       "29  LP001087  Female      No          2      Graduate           NaN   \n",
       "..       ...     ...     ...        ...           ...           ...   \n",
       "70  LP001243    Male     Yes          0      Graduate            No   \n",
       "71  LP001245    Male     Yes          2  Not Graduate           Yes   \n",
       "72  LP001248    Male      No          0      Graduate            No   \n",
       "73  LP001250    Male     Yes         3+  Not Graduate            No   \n",
       "74  LP001253    Male     Yes         3+      Graduate           Yes   \n",
       "75  LP001255    Male      No          0      Graduate            No   \n",
       "76  LP001256    Male      No          0      Graduate            No   \n",
       "77  LP001259    Male     Yes          1      Graduate           Yes   \n",
       "78  LP001263    Male     Yes         3+      Graduate            No   \n",
       "79  LP001264    Male     Yes         3+  Not Graduate           Yes   \n",
       "80  LP001265  Female      No          0      Graduate            No   \n",
       "81  LP001266    Male     Yes          1      Graduate           Yes   \n",
       "82  LP001267  Female     Yes          2      Graduate            No   \n",
       "83  LP001273    Male     Yes          0      Graduate            No   \n",
       "84  LP001275    Male     Yes          1      Graduate            No   \n",
       "85  LP001279    Male      No          0      Graduate            No   \n",
       "86  LP001280    Male     Yes          2  Not Graduate            No   \n",
       "87  LP001282    Male     Yes          0      Graduate            No   \n",
       "88  LP001289    Male      No          0      Graduate            No   \n",
       "89  LP001310    Male     Yes          0      Graduate            No   \n",
       "90  LP001316    Male     Yes          0      Graduate            No   \n",
       "91  LP001318    Male     Yes          2      Graduate            No   \n",
       "92  LP001319    Male     Yes          2  Not Graduate            No   \n",
       "93  LP001322    Male      No          0      Graduate            No   \n",
       "94  LP001325    Male      No          0  Not Graduate            No   \n",
       "95  LP001326    Male      No          0      Graduate           NaN   \n",
       "96  LP001327  Female     Yes          0      Graduate            No   \n",
       "97  LP001333    Male     Yes          0      Graduate            No   \n",
       "98  LP001334    Male     Yes          0  Not Graduate            No   \n",
       "99  LP001343    Male     Yes          0      Graduate            No   \n",
       "\n",
       "    ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0              5849                0.0         NaN             360.0   \n",
       "1              4583             1508.0       128.0             360.0   \n",
       "2              3000                0.0        66.0             360.0   \n",
       "3              2583             2358.0       120.0             360.0   \n",
       "4              6000                0.0       141.0             360.0   \n",
       "5              5417             4196.0       267.0             360.0   \n",
       "6              2333             1516.0        95.0             360.0   \n",
       "7              3036             2504.0       158.0             360.0   \n",
       "8              4006             1526.0       168.0             360.0   \n",
       "9             12841            10968.0       349.0             360.0   \n",
       "10             3200              700.0        70.0             360.0   \n",
       "11             2500             1840.0       109.0             360.0   \n",
       "12             3073             8106.0       200.0             360.0   \n",
       "13             1853             2840.0       114.0             360.0   \n",
       "14             1299             1086.0        17.0             120.0   \n",
       "15             4950                0.0       125.0             360.0   \n",
       "16             3596                0.0       100.0             240.0   \n",
       "17             3510                0.0        76.0             360.0   \n",
       "18             4887                0.0       133.0             360.0   \n",
       "19             2600             3500.0       115.0               NaN   \n",
       "20             7660                0.0       104.0             360.0   \n",
       "21             5955             5625.0       315.0             360.0   \n",
       "22             2600             1911.0       116.0             360.0   \n",
       "23             3365             1917.0       112.0             360.0   \n",
       "24             3717             2925.0       151.0             360.0   \n",
       "25             9560                0.0       191.0             360.0   \n",
       "26             2799             2253.0       122.0             360.0   \n",
       "27             4226             1040.0       110.0             360.0   \n",
       "28             1442                0.0        35.0             360.0   \n",
       "29             3750             2083.0       120.0             360.0   \n",
       "..              ...                ...         ...               ...   \n",
       "70             3208             3066.0       172.0             360.0   \n",
       "71             1875             1875.0        97.0             360.0   \n",
       "72             3500                0.0        81.0             300.0   \n",
       "73             4755                0.0        95.0               NaN   \n",
       "74             5266             1774.0       187.0             360.0   \n",
       "75             3750                0.0       113.0             480.0   \n",
       "76             3750             4750.0       176.0             360.0   \n",
       "77             1000             3022.0       110.0             360.0   \n",
       "78             3167             4000.0       180.0             300.0   \n",
       "79             3333             2166.0       130.0             360.0   \n",
       "80             3846                0.0       111.0             360.0   \n",
       "81             2395                0.0         NaN             360.0   \n",
       "82             1378             1881.0       167.0             360.0   \n",
       "83             6000             2250.0       265.0             360.0   \n",
       "84             3988                0.0        50.0             240.0   \n",
       "85             2366             2531.0       136.0             360.0   \n",
       "86             3333             2000.0        99.0             360.0   \n",
       "87             2500             2118.0       104.0             360.0   \n",
       "88             8566                0.0       210.0             360.0   \n",
       "89             5695             4167.0       175.0             360.0   \n",
       "90             2958             2900.0       131.0             360.0   \n",
       "91             6250             5654.0       188.0             180.0   \n",
       "92             3273             1820.0        81.0             360.0   \n",
       "93             4133                0.0       122.0             360.0   \n",
       "94             3620                0.0        25.0             120.0   \n",
       "95             6782                0.0         NaN             360.0   \n",
       "96             2484             2302.0       137.0             360.0   \n",
       "97             1977              997.0        50.0             360.0   \n",
       "98             4188                0.0       115.0             180.0   \n",
       "99             1759             3541.0       131.0             360.0   \n",
       "\n",
       "    Credit_History Property_Area Loan_Status  \n",
       "0              1.0         Urban           Y  \n",
       "1              1.0         Rural           N  \n",
       "2              1.0         Urban           Y  \n",
       "3              1.0         Urban           Y  \n",
       "4              1.0         Urban           Y  \n",
       "5              1.0         Urban           Y  \n",
       "6              1.0         Urban           Y  \n",
       "7              0.0     Semiurban           N  \n",
       "8              1.0         Urban           Y  \n",
       "9              1.0     Semiurban           N  \n",
       "10             1.0         Urban           Y  \n",
       "11             1.0         Urban           Y  \n",
       "12             1.0         Urban           Y  \n",
       "13             1.0         Rural           N  \n",
       "14             1.0         Urban           Y  \n",
       "15             1.0         Urban           Y  \n",
       "16             NaN         Urban           Y  \n",
       "17             0.0         Urban           N  \n",
       "18             1.0         Rural           N  \n",
       "19             1.0         Urban           Y  \n",
       "20             0.0         Urban           N  \n",
       "21             1.0         Urban           Y  \n",
       "22             0.0     Semiurban           N  \n",
       "23             0.0         Rural           N  \n",
       "24             NaN     Semiurban           N  \n",
       "25             1.0     Semiurban           Y  \n",
       "26             1.0     Semiurban           Y  \n",
       "27             1.0         Urban           Y  \n",
       "28             1.0         Urban           N  \n",
       "29             1.0     Semiurban           Y  \n",
       "..             ...           ...         ...  \n",
       "70             1.0         Urban           Y  \n",
       "71             1.0     Semiurban           Y  \n",
       "72             1.0     Semiurban           Y  \n",
       "73             0.0     Semiurban           N  \n",
       "74             1.0     Semiurban           Y  \n",
       "75             1.0         Urban           N  \n",
       "76             1.0         Urban           N  \n",
       "77             1.0         Urban           N  \n",
       "78             0.0     Semiurban           N  \n",
       "79             NaN     Semiurban           Y  \n",
       "80             1.0     Semiurban           Y  \n",
       "81             1.0     Semiurban           Y  \n",
       "82             1.0         Urban           N  \n",
       "83             NaN     Semiurban           N  \n",
       "84             1.0         Urban           Y  \n",
       "85             1.0     Semiurban           Y  \n",
       "86             NaN     Semiurban           Y  \n",
       "87             1.0     Semiurban           Y  \n",
       "88             1.0         Urban           Y  \n",
       "89             1.0     Semiurban           Y  \n",
       "90             1.0     Semiurban           Y  \n",
       "91             1.0     Semiurban           Y  \n",
       "92             1.0         Urban           Y  \n",
       "93             1.0     Semiurban           Y  \n",
       "94             1.0     Semiurban           Y  \n",
       "95             NaN         Urban           N  \n",
       "96             1.0     Semiurban           Y  \n",
       "97             1.0     Semiurban           Y  \n",
       "98             1.0     Semiurban           Y  \n",
       "99             1.0     Semiurban           Y  \n",
       "\n",
       "[100 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_original=train.copy()\n",
    "test_original=test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((614, 13), (367, 12))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Loan_ID', 'Gender', 'Married', 'Dependents', 'Education',\n",
       "       'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',\n",
       "       'Loan_Amount_Term', 'Credit_History', 'Property_Area', 'Loan_Status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y    422\n",
       "N    192\n",
       "Name: Loan_Status, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Loan_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y    0.687296\n",
       "N    0.312704\n",
       "Name: Loan_Status, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize can be set to True to print proportions instead of number \n",
    "train['Loan_Status'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19dff6d0fd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD5CAYAAAAp8/5SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19dff5652e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['Loan_Status'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIQAAAJWCAYAAAAp9FwoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSysAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19dff9b8748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.subplot(221)\n",
    "train['Gender'].value_counts(normalize=True).plot.bar(figsize=(20,10), title= 'Gender')\n",
    "\n",
    "plt.subplot(222)\n",
    "train['Married'].value_counts(normalize=True).plot.bar(title= 'Married')\n",
    "\n",
    "plt.subplot(223)\n",
    "train['Self_Employed'].value_counts(normalize=True).plot.bar(title= 'Self_Employed')\n",
    "\n",
    "plt.subplot(224)\n",
    "train['Credit_History'].value_counts(normalize=True).plot.bar(title= 'Credit_History')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID               0\n",
       "Gender               13\n",
       "Married               3\n",
       "Dependents           15\n",
       "Education             0\n",
       "Self_Employed        32\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount           22\n",
       "Loan_Amount_Term     14\n",
       "Credit_History       50\n",
       "Property_Area         0\n",
       "Loan_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Gender'].fillna(train['Gender'].mode()[0], inplace=True)\n",
    "train['Married'].fillna(train['Married'].mode()[0], inplace=True)\n",
    "train['Dependents'].fillna(train['Dependents'].mode()[0], inplace=True)\n",
    "train['Self_Employed'].fillna(train['Self_Employed'].mode()[0], inplace=True)\n",
    "train['Credit_History'].fillna(train['Credit_History'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360.0    512\n",
       "180.0     44\n",
       "480.0     15\n",
       "300.0     13\n",
       "84.0       4\n",
       "240.0      4\n",
       "120.0      3\n",
       "36.0       2\n",
       "60.0       2\n",
       "12.0       1\n",
       "Name: Loan_Amount_Term, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Loan_Amount_Term'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Loan_Amount_Term'].fillna(train['Loan_Amount_Term'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['LoanAmount'].fillna(train['LoanAmount'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID              0\n",
       "Gender               0\n",
       "Married              0\n",
       "Dependents           0\n",
       "Education            0\n",
       "Self_Employed        0\n",
       "ApplicantIncome      0\n",
       "CoapplicantIncome    0\n",
       "LoanAmount           0\n",
       "Loan_Amount_Term     0\n",
       "Credit_History       0\n",
       "Property_Area        0\n",
       "Loan_Status          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=train.drop('Loan_ID',axis=1)\n",
    "test=test.drop('Loan_ID',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train.drop('Loan_Status',1)\n",
    "y = train.Loan_Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=pd.get_dummies(X)\n",
    "train=pd.get_dummies(train)\n",
    "test=pd.get_dummies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "le=LabelEncoder()\n",
    "y=le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(429, 20)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_cv, y_train, y_cv = train_test_split(X,y, test_size =0.3)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model= Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(units=6, kernel_initializer=\"uniform\", activation= \"relu\", input_dim=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dropout(p=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(units=6, kernel_initializer=\"uniform\", activation= \"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(units=1, kernel_initializer=\"uniform\", activation= \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#if more than one dependant variables, use Softmax and make output dim as no of dependant varibles\n",
    "#also use performance tuning\n",
    "#more than one dependant othr loss function\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "429/429 [==============================] - 0s 707us/step - loss: 0.6994 - acc: 0.5152\n",
      "Epoch 2/50\n",
      "429/429 [==============================] - 0s 60us/step - loss: 0.6781 - acc: 0.6807\n",
      "Epoch 3/50\n",
      "429/429 [==============================] - 0s 60us/step - loss: 0.6606 - acc: 0.6876\n",
      "Epoch 4/50\n",
      "429/429 [==============================] - 0s 72us/step - loss: 0.6570 - acc: 0.6853\n",
      "Epoch 5/50\n",
      "429/429 [==============================] - 0s 67us/step - loss: 0.6464 - acc: 0.6876\n",
      "Epoch 6/50\n",
      "429/429 [==============================] - 0s 72us/step - loss: 0.6446 - acc: 0.6923\n",
      "Epoch 7/50\n",
      "429/429 [==============================] - 0s 56us/step - loss: 0.6484 - acc: 0.6853\n",
      "Epoch 8/50\n",
      "429/429 [==============================] - 0s 72us/step - loss: 0.6450 - acc: 0.6900\n",
      "Epoch 9/50\n",
      "429/429 [==============================] - 0s 77us/step - loss: 0.6423 - acc: 0.6876\n",
      "Epoch 10/50\n",
      "429/429 [==============================] - 0s 72us/step - loss: 0.6498 - acc: 0.6876\n",
      "Epoch 11/50\n",
      "429/429 [==============================] - 0s 81us/step - loss: 0.6388 - acc: 0.6876\n",
      "Epoch 12/50\n",
      "429/429 [==============================] - 0s 86us/step - loss: 0.6422 - acc: 0.6853\n",
      "Epoch 13/50\n",
      "429/429 [==============================] - 0s 91us/step - loss: 0.6362 - acc: 0.6923\n",
      "Epoch 14/50\n",
      "429/429 [==============================] - 0s 60us/step - loss: 0.6331 - acc: 0.6900\n",
      "Epoch 15/50\n",
      "429/429 [==============================] - 0s 65us/step - loss: 0.6411 - acc: 0.6853\n",
      "Epoch 16/50\n",
      "429/429 [==============================] - 0s 77us/step - loss: 0.6292 - acc: 0.6876\n",
      "Epoch 17/50\n",
      "429/429 [==============================] - 0s 74us/step - loss: 0.6341 - acc: 0.6876\n",
      "Epoch 18/50\n",
      "429/429 [==============================] - 0s 60us/step - loss: 0.6448 - acc: 0.6876\n",
      "Epoch 19/50\n",
      "429/429 [==============================] - 0s 63us/step - loss: 0.6298 - acc: 0.6876\n",
      "Epoch 20/50\n",
      "429/429 [==============================] - 0s 58us/step - loss: 0.6295 - acc: 0.6853\n",
      "Epoch 21/50\n",
      "429/429 [==============================] - 0s 65us/step - loss: 0.6290 - acc: 0.6876\n",
      "Epoch 22/50\n",
      "429/429 [==============================] - 0s 67us/step - loss: 0.6276 - acc: 0.6876\n",
      "Epoch 23/50\n",
      "429/429 [==============================] - 0s 56us/step - loss: 0.6263 - acc: 0.6853\n",
      "Epoch 24/50\n",
      "429/429 [==============================] - 0s 58us/step - loss: 0.6282 - acc: 0.6900\n",
      "Epoch 25/50\n",
      "429/429 [==============================] - 0s 63us/step - loss: 0.6261 - acc: 0.6876\n",
      "Epoch 26/50\n",
      "429/429 [==============================] - 0s 60us/step - loss: 0.6251 - acc: 0.6876\n",
      "Epoch 27/50\n",
      "429/429 [==============================] - 0s 58us/step - loss: 0.6203 - acc: 0.6876\n",
      "Epoch 28/50\n",
      "429/429 [==============================] - 0s 63us/step - loss: 0.6279 - acc: 0.6900\n",
      "Epoch 29/50\n",
      "429/429 [==============================] - 0s 77us/step - loss: 0.6272 - acc: 0.6900\n",
      "Epoch 30/50\n",
      "429/429 [==============================] - 0s 58us/step - loss: 0.6251 - acc: 0.6900\n",
      "Epoch 31/50\n",
      "429/429 [==============================] - ETA: 0s - loss: 0.6882 - acc: 0.550 - 0s 67us/step - loss: 0.6245 - acc: 0.6876\n",
      "Epoch 32/50\n",
      "429/429 [==============================] - 0s 60us/step - loss: 0.6275 - acc: 0.6876\n",
      "Epoch 33/50\n",
      "429/429 [==============================] - 0s 56us/step - loss: 0.6158 - acc: 0.6830\n",
      "Epoch 34/50\n",
      "429/429 [==============================] - 0s 56us/step - loss: 0.6218 - acc: 0.6807\n",
      "Epoch 35/50\n",
      "429/429 [==============================] - 0s 60us/step - loss: 0.6248 - acc: 0.6853\n",
      "Epoch 36/50\n",
      "429/429 [==============================] - 0s 46us/step - loss: 0.6261 - acc: 0.6876\n",
      "Epoch 37/50\n",
      "429/429 [==============================] - 0s 65us/step - loss: 0.6205 - acc: 0.6900\n",
      "Epoch 38/50\n",
      "429/429 [==============================] - 0s 53us/step - loss: 0.6213 - acc: 0.6900\n",
      "Epoch 39/50\n",
      "429/429 [==============================] - 0s 58us/step - loss: 0.6217 - acc: 0.6853\n",
      "Epoch 40/50\n",
      "429/429 [==============================] - 0s 46us/step - loss: 0.6304 - acc: 0.6876\n",
      "Epoch 41/50\n",
      "429/429 [==============================] - 0s 56us/step - loss: 0.6269 - acc: 0.6900\n",
      "Epoch 42/50\n",
      "429/429 [==============================] - 0s 44us/step - loss: 0.6244 - acc: 0.6876\n",
      "Epoch 43/50\n",
      "429/429 [==============================] - 0s 74us/step - loss: 0.6268 - acc: 0.6876\n",
      "Epoch 44/50\n",
      "429/429 [==============================] - 0s 63us/step - loss: 0.6182 - acc: 0.6876\n",
      "Epoch 45/50\n",
      "429/429 [==============================] - 0s 56us/step - loss: 0.6212 - acc: 0.6853\n",
      "Epoch 46/50\n",
      "429/429 [==============================] - 0s 56us/step - loss: 0.6243 - acc: 0.6876\n",
      "Epoch 47/50\n",
      "429/429 [==============================] - 0s 65us/step - loss: 0.6180 - acc: 0.6900\n",
      "Epoch 48/50\n",
      "429/429 [==============================] - 0s 65us/step - loss: 0.6209 - acc: 0.6853\n",
      "Epoch 49/50\n",
      "429/429 [==============================] - 0s 51us/step - loss: 0.6175 - acc: 0.6876\n",
      "Epoch 50/50\n",
      "429/429 [==============================] - 0s 65us/step - loss: 0.6220 - acc: 0.6853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19d86893828>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=20, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_cv = model.predict(x_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for x in pred_cv:\n",
    "    if x>0.5:\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(0)\n",
    "\n",
    "predictions= pd.Series(predictions)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69729729729729728"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_cv,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Performance Tuning\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model= Sequential()\n",
    "    model.add(Dense(units=6, kernel_initializer=\"uniform\", activation= \"relu\", input_dim=20))\n",
    "    model.add(Dense(units=6, kernel_initializer=\"uniform\", activation= \"relu\"))\n",
    "    model.add(Dense(units=1, kernel_initializer=\"uniform\", activation= \"sigmoid\"))\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model= KerasClassifier(build_fn= build_model, batch_size=10, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.6590 - acc: 0.6888\n",
      "Epoch 2/50\n",
      "286/286 [==============================] - 0s 115us/step - loss: 0.6440 - acc: 0.6853\n",
      "Epoch 3/50\n",
      "286/286 [==============================] - 0s 129us/step - loss: 0.6387 - acc: 0.6853\n",
      "Epoch 4/50\n",
      "286/286 [==============================] - 0s 119us/step - loss: 0.6411 - acc: 0.6853\n",
      "Epoch 5/50\n",
      "286/286 [==============================] - 0s 87us/step - loss: 0.6382 - acc: 0.6853\n",
      "Epoch 6/50\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.6006 - acc: 0.700 - 0s 122us/step - loss: 0.6351 - acc: 0.6853\n",
      "Epoch 7/50\n",
      "286/286 [==============================] - 0s 126us/step - loss: 0.6362 - acc: 0.6853\n",
      "Epoch 8/50\n",
      "286/286 [==============================] - 0s 122us/step - loss: 0.6361 - acc: 0.6888\n",
      "Epoch 9/50\n",
      "286/286 [==============================] - 0s 108us/step - loss: 0.6339 - acc: 0.6888\n",
      "Epoch 10/50\n",
      "286/286 [==============================] - 0s 139us/step - loss: 0.6316 - acc: 0.6888\n",
      "Epoch 11/50\n",
      "286/286 [==============================] - 0s 108us/step - loss: 0.6336 - acc: 0.6853\n",
      "Epoch 12/50\n",
      "286/286 [==============================] - 0s 112us/step - loss: 0.6282 - acc: 0.6853\n",
      "Epoch 13/50\n",
      "286/286 [==============================] - 0s 126us/step - loss: 0.6280 - acc: 0.6888\n",
      "Epoch 14/50\n",
      "286/286 [==============================] - 0s 108us/step - loss: 0.6284 - acc: 0.6818\n",
      "Epoch 15/50\n",
      "286/286 [==============================] - 0s 122us/step - loss: 0.6303 - acc: 0.6853\n",
      "Epoch 16/50\n",
      "286/286 [==============================] - 0s 108us/step - loss: 0.6265 - acc: 0.6853\n",
      "Epoch 17/50\n",
      "286/286 [==============================] - 0s 112us/step - loss: 0.6240 - acc: 0.6888\n",
      "Epoch 18/50\n",
      "286/286 [==============================] - 0s 119us/step - loss: 0.6276 - acc: 0.6888\n",
      "Epoch 19/50\n",
      "286/286 [==============================] - 0s 119us/step - loss: 0.6234 - acc: 0.6853\n",
      "Epoch 20/50\n",
      "286/286 [==============================] - 0s 150us/step - loss: 0.6278 - acc: 0.6888\n",
      "Epoch 21/50\n",
      "286/286 [==============================] - 0s 136us/step - loss: 0.6249 - acc: 0.6888\n",
      "Epoch 22/50\n",
      "286/286 [==============================] - 0s 133us/step - loss: 0.6209 - acc: 0.6888\n",
      "Epoch 23/50\n",
      "286/286 [==============================] - 0s 112us/step - loss: 0.6244 - acc: 0.6853\n",
      "Epoch 24/50\n",
      "286/286 [==============================] - 0s 129us/step - loss: 0.6214 - acc: 0.6853\n",
      "Epoch 25/50\n",
      "286/286 [==============================] - 0s 105us/step - loss: 0.6206 - acc: 0.6888\n",
      "Epoch 26/50\n",
      "286/286 [==============================] - 0s 108us/step - loss: 0.6237 - acc: 0.6888\n",
      "Epoch 27/50\n",
      "286/286 [==============================] - 0s 126us/step - loss: 0.6213 - acc: 0.6888\n",
      "Epoch 28/50\n",
      "286/286 [==============================] - 0s 154us/step - loss: 0.6229 - acc: 0.6888\n",
      "Epoch 29/50\n",
      "286/286 [==============================] - 0s 126us/step - loss: 0.6187 - acc: 0.6888\n",
      "Epoch 30/50\n",
      "286/286 [==============================] - 0s 105us/step - loss: 0.6305 - acc: 0.6888\n",
      "Epoch 31/50\n",
      "286/286 [==============================] - 0s 133us/step - loss: 0.6240 - acc: 0.6888\n",
      "Epoch 32/50\n",
      "286/286 [==============================] - 0s 126us/step - loss: 0.6213 - acc: 0.6888\n",
      "Epoch 33/50\n",
      "286/286 [==============================] - 0s 115us/step - loss: 0.6234 - acc: 0.6888\n",
      "Epoch 34/50\n",
      "286/286 [==============================] - 0s 91us/step - loss: 0.6190 - acc: 0.6888\n",
      "Epoch 35/50\n",
      "286/286 [==============================] - 0s 105us/step - loss: 0.6188 - acc: 0.6888\n",
      "Epoch 36/50\n",
      "286/286 [==============================] - 0s 101us/step - loss: 0.6182 - acc: 0.6923\n",
      "Epoch 37/50\n",
      "286/286 [==============================] - 0s 101us/step - loss: 0.6291 - acc: 0.6853\n",
      "Epoch 38/50\n",
      "286/286 [==============================] - 0s 122us/step - loss: 0.6183 - acc: 0.6888\n",
      "Epoch 39/50\n",
      "286/286 [==============================] - 0s 101us/step - loss: 0.6191 - acc: 0.6888\n",
      "Epoch 40/50\n",
      "286/286 [==============================] - 0s 115us/step - loss: 0.6187 - acc: 0.6853\n",
      "Epoch 41/50\n",
      "286/286 [==============================] - 0s 115us/step - loss: 0.6198 - acc: 0.6888\n",
      "Epoch 42/50\n",
      "286/286 [==============================] - 0s 105us/step - loss: 0.6174 - acc: 0.6888\n",
      "Epoch 43/50\n",
      "286/286 [==============================] - 0s 119us/step - loss: 0.6168 - acc: 0.6888\n",
      "Epoch 44/50\n",
      "286/286 [==============================] - 0s 122us/step - loss: 0.6194 - acc: 0.6888\n",
      "Epoch 45/50\n",
      "286/286 [==============================] - 0s 101us/step - loss: 0.6159 - acc: 0.6853\n",
      "Epoch 46/50\n",
      "286/286 [==============================] - 0s 108us/step - loss: 0.6197 - acc: 0.6888\n",
      "Epoch 47/50\n",
      "286/286 [==============================] - 0s 122us/step - loss: 0.6167 - acc: 0.6888\n",
      "Epoch 48/50\n",
      "286/286 [==============================] - 0s 119us/step - loss: 0.6177 - acc: 0.6923\n",
      "Epoch 49/50\n",
      "286/286 [==============================] - 0s 153us/step - loss: 0.6171 - acc: 0.6853\n",
      "Epoch 50/50\n",
      "286/286 [==============================] - 0s 112us/step - loss: 0.6198 - acc: 0.6923\n",
      "143/143 [==============================] - 0s 830us/step\n",
      "Epoch 1/50\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.7002 - acc: 0.6014\n",
      "Epoch 2/50\n",
      "286/286 [==============================] - 0s 112us/step - loss: 0.6608 - acc: 0.7028\n",
      "Epoch 3/50\n",
      "286/286 [==============================] - 0s 129us/step - loss: 0.6541 - acc: 0.7028\n",
      "Epoch 4/50\n",
      "286/286 [==============================] - 0s 91us/step - loss: 0.6471 - acc: 0.6748\n",
      "Epoch 5/50\n",
      "286/286 [==============================] - 0s 119us/step - loss: 0.6331 - acc: 0.7028\n",
      "Epoch 6/50\n",
      "286/286 [==============================] - 0s 112us/step - loss: 0.6311 - acc: 0.6888\n",
      "Epoch 7/50\n",
      "286/286 [==============================] - 0s 115us/step - loss: 0.6320 - acc: 0.7063\n",
      "Epoch 8/50\n",
      "286/286 [==============================] - 0s 115us/step - loss: 0.6166 - acc: 0.6993\n",
      "Epoch 9/50\n",
      "286/286 [==============================] - 0s 108us/step - loss: 0.6178 - acc: 0.6993\n",
      "Epoch 10/50\n",
      "286/286 [==============================] - 0s 115us/step - loss: 0.6300 - acc: 0.6923\n",
      "Epoch 11/50\n",
      "286/286 [==============================] - 0s 112us/step - loss: 0.6180 - acc: 0.7028\n",
      "Epoch 12/50\n",
      "286/286 [==============================] - 0s 112us/step - loss: 0.6116 - acc: 0.7028\n",
      "Epoch 13/50\n",
      "286/286 [==============================] - 0s 122us/step - loss: 0.6132 - acc: 0.6958\n",
      "Epoch 14/50\n",
      "286/286 [==============================] - 0s 98us/step - loss: 0.6127 - acc: 0.7028\n",
      "Epoch 15/50\n",
      "286/286 [==============================] - 0s 112us/step - loss: 0.6109 - acc: 0.7028\n",
      "Epoch 16/50\n",
      "286/286 [==============================] - 0s 101us/step - loss: 0.6083 - acc: 0.7063\n",
      "Epoch 17/50\n",
      "286/286 [==============================] - 0s 108us/step - loss: 0.6268 - acc: 0.6958\n",
      "Epoch 18/50\n",
      "286/286 [==============================] - 0s 115us/step - loss: 0.6163 - acc: 0.6888\n",
      "Epoch 19/50\n",
      "286/286 [==============================] - 0s 105us/step - loss: 0.6094 - acc: 0.7028\n",
      "Epoch 20/50\n",
      "286/286 [==============================] - 0s 136us/step - loss: 0.6036 - acc: 0.7028\n",
      "Epoch 21/50\n",
      "286/286 [==============================] - 0s 112us/step - loss: 0.6029 - acc: 0.7098\n",
      "Epoch 22/50\n",
      "286/286 [==============================] - 0s 112us/step - loss: 0.6061 - acc: 0.7063\n",
      "Epoch 23/50\n",
      "286/286 [==============================] - 0s 112us/step - loss: 0.6005 - acc: 0.7028\n",
      "Epoch 24/50\n",
      "286/286 [==============================] - 0s 108us/step - loss: 0.6065 - acc: 0.6958\n",
      "Epoch 25/50\n",
      "286/286 [==============================] - 0s 87us/step - loss: 0.6056 - acc: 0.6993\n",
      "Epoch 26/50\n",
      "286/286 [==============================] - 0s 119us/step - loss: 0.5988 - acc: 0.7063\n",
      "Epoch 27/50\n",
      "286/286 [==============================] - 0s 108us/step - loss: 0.6029 - acc: 0.7028\n",
      "Epoch 28/50\n",
      "286/286 [==============================] - 0s 105us/step - loss: 0.6025 - acc: 0.7063\n",
      "Epoch 29/50\n",
      "286/286 [==============================] - 0s 129us/step - loss: 0.6043 - acc: 0.6993\n",
      "Epoch 30/50\n",
      "286/286 [==============================] - 0s 98us/step - loss: 0.6108 - acc: 0.7028\n",
      "Epoch 31/50\n",
      "286/286 [==============================] - 0s 91us/step - loss: 0.6058 - acc: 0.6993\n",
      "Epoch 32/50\n",
      "286/286 [==============================] - 0s 129us/step - loss: 0.5980 - acc: 0.7063\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 0s 94us/step - loss: 0.5992 - acc: 0.7063\n",
      "Epoch 34/50\n",
      "286/286 [==============================] - 0s 122us/step - loss: 0.5994 - acc: 0.7028\n",
      "Epoch 35/50\n",
      "286/286 [==============================] - 0s 112us/step - loss: 0.5975 - acc: 0.7028\n",
      "Epoch 36/50\n",
      "286/286 [==============================] - 0s 108us/step - loss: 0.6022 - acc: 0.6888\n",
      "Epoch 37/50\n",
      "286/286 [==============================] - 0s 98us/step - loss: 0.5964 - acc: 0.7098\n",
      "Epoch 38/50\n",
      "286/286 [==============================] - 0s 94us/step - loss: 0.5960 - acc: 0.6993\n",
      "Epoch 39/50\n",
      "286/286 [==============================] - 0s 119us/step - loss: 0.5889 - acc: 0.7028\n",
      "Epoch 40/50\n",
      "286/286 [==============================] - 0s 94us/step - loss: 0.6036 - acc: 0.7028\n",
      "Epoch 41/50\n",
      "286/286 [==============================] - 0s 108us/step - loss: 0.5924 - acc: 0.7098\n",
      "Epoch 42/50\n",
      "286/286 [==============================] - 0s 119us/step - loss: 0.5946 - acc: 0.7028\n",
      "Epoch 43/50\n",
      "286/286 [==============================] - 0s 126us/step - loss: 0.5904 - acc: 0.7028\n",
      "Epoch 44/50\n",
      "286/286 [==============================] - 0s 126us/step - loss: 0.5910 - acc: 0.7028\n",
      "Epoch 45/50\n",
      "286/286 [==============================] - 0s 94us/step - loss: 0.5966 - acc: 0.7098\n",
      "Epoch 46/50\n",
      "286/286 [==============================] - 0s 108us/step - loss: 0.5904 - acc: 0.7028\n",
      "Epoch 47/50\n",
      "286/286 [==============================] - 0s 105us/step - loss: 0.5870 - acc: 0.7028\n",
      "Epoch 48/50\n",
      "286/286 [==============================] - 0s 115us/step - loss: 0.5963 - acc: 0.7098\n",
      "Epoch 49/50\n",
      "286/286 [==============================] - 0s 115us/step - loss: 0.5873 - acc: 0.7063\n",
      "Epoch 50/50\n",
      "286/286 [==============================] - 0s 112us/step - loss: 0.5898 - acc: 0.7028\n",
      "143/143 [==============================] - 0s 663us/step\n",
      "Epoch 1/50\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.7103 - acc: 0.4860\n",
      "Epoch 2/50\n",
      "286/286 [==============================] - 0s 122us/step - loss: 0.6618 - acc: 0.6748\n",
      "Epoch 3/50\n",
      "286/286 [==============================] - 0s 101us/step - loss: 0.6610 - acc: 0.6748\n",
      "Epoch 4/50\n",
      "286/286 [==============================] - 0s 115us/step - loss: 0.6558 - acc: 0.6748\n",
      "Epoch 5/50\n",
      "286/286 [==============================] - 0s 112us/step - loss: 0.6556 - acc: 0.6748\n",
      "Epoch 6/50\n",
      "286/286 [==============================] - 0s 101us/step - loss: 0.6544 - acc: 0.6748\n",
      "Epoch 7/50\n",
      "286/286 [==============================] - 0s 87us/step - loss: 0.6520 - acc: 0.6748\n",
      "Epoch 8/50\n",
      "286/286 [==============================] - 0s 108us/step - loss: 0.6529 - acc: 0.6748\n",
      "Epoch 9/50\n",
      "286/286 [==============================] - 0s 108us/step - loss: 0.6502 - acc: 0.6748\n",
      "Epoch 10/50\n",
      "286/286 [==============================] - 0s 112us/step - loss: 0.6490 - acc: 0.6748\n",
      "Epoch 11/50\n",
      "286/286 [==============================] - 0s 105us/step - loss: 0.6535 - acc: 0.6748\n",
      "Epoch 12/50\n",
      "286/286 [==============================] - 0s 105us/step - loss: 0.6468 - acc: 0.6748\n",
      "Epoch 13/50\n",
      "286/286 [==============================] - 0s 108us/step - loss: 0.6482 - acc: 0.6748\n",
      "Epoch 14/50\n",
      "286/286 [==============================] - 0s 105us/step - loss: 0.6455 - acc: 0.6748\n",
      "Epoch 15/50\n",
      "286/286 [==============================] - 0s 91us/step - loss: 0.6471 - acc: 0.6748\n",
      "Epoch 16/50\n",
      "286/286 [==============================] - 0s 101us/step - loss: 0.6427 - acc: 0.6748\n",
      "Epoch 17/50\n",
      "286/286 [==============================] - 0s 115us/step - loss: 0.6415 - acc: 0.6748\n",
      "Epoch 18/50\n",
      "286/286 [==============================] - 0s 115us/step - loss: 0.6416 - acc: 0.6748\n",
      "Epoch 19/50\n",
      "286/286 [==============================] - 0s 112us/step - loss: 0.6417 - acc: 0.6748\n",
      "Epoch 20/50\n",
      "286/286 [==============================] - 0s 112us/step - loss: 0.6412 - acc: 0.6748\n",
      "Epoch 21/50\n",
      "286/286 [==============================] - 0s 115us/step - loss: 0.6393 - acc: 0.6748\n",
      "Epoch 22/50\n",
      "286/286 [==============================] - 0s 153us/step - loss: 0.6382 - acc: 0.6748\n",
      "Epoch 23/50\n",
      "286/286 [==============================] - 0s 101us/step - loss: 0.6447 - acc: 0.6748\n",
      "Epoch 24/50\n",
      "286/286 [==============================] - 0s 108us/step - loss: 0.6367 - acc: 0.6748\n",
      "Epoch 25/50\n",
      "286/286 [==============================] - 0s 126us/step - loss: 0.6380 - acc: 0.6748\n",
      "Epoch 26/50\n",
      "286/286 [==============================] - 0s 105us/step - loss: 0.6355 - acc: 0.6748\n",
      "Epoch 27/50\n",
      "286/286 [==============================] - 0s 115us/step - loss: 0.6357 - acc: 0.6748\n",
      "Epoch 28/50\n",
      "286/286 [==============================] - 0s 105us/step - loss: 0.6346 - acc: 0.6748\n",
      "Epoch 29/50\n",
      "286/286 [==============================] - 0s 119us/step - loss: 0.6337 - acc: 0.6748\n",
      "Epoch 30/50\n",
      "286/286 [==============================] - 0s 112us/step - loss: 0.6340 - acc: 0.6748\n",
      "Epoch 31/50\n",
      "286/286 [==============================] - 0s 98us/step - loss: 0.6322 - acc: 0.6748\n",
      "Epoch 32/50\n",
      "286/286 [==============================] - 0s 101us/step - loss: 0.6323 - acc: 0.6748\n",
      "Epoch 33/50\n",
      "286/286 [==============================] - 0s 115us/step - loss: 0.6346 - acc: 0.6748\n",
      "Epoch 34/50\n",
      "286/286 [==============================] - 0s 105us/step - loss: 0.6340 - acc: 0.6748\n",
      "Epoch 35/50\n",
      "286/286 [==============================] - 0s 108us/step - loss: 0.6324 - acc: 0.6748\n",
      "Epoch 36/50\n",
      "286/286 [==============================] - 0s 91us/step - loss: 0.6363 - acc: 0.6748\n",
      "Epoch 37/50\n",
      "286/286 [==============================] - 0s 126us/step - loss: 0.6310 - acc: 0.6748\n",
      "Epoch 38/50\n",
      "286/286 [==============================] - 0s 136us/step - loss: 0.6344 - acc: 0.6748\n",
      "Epoch 39/50\n",
      "286/286 [==============================] - 0s 129us/step - loss: 0.6315 - acc: 0.6748\n",
      "Epoch 40/50\n",
      "286/286 [==============================] - 0s 136us/step - loss: 0.6281 - acc: 0.6748\n",
      "Epoch 41/50\n",
      "286/286 [==============================] - 0s 122us/step - loss: 0.6321 - acc: 0.6748\n",
      "Epoch 42/50\n",
      "286/286 [==============================] - 0s 115us/step - loss: 0.6292 - acc: 0.6748\n",
      "Epoch 43/50\n",
      "286/286 [==============================] - 0s 105us/step - loss: 0.6300 - acc: 0.6748\n",
      "Epoch 44/50\n",
      "286/286 [==============================] - 0s 129us/step - loss: 0.6308 - acc: 0.6748\n",
      "Epoch 45/50\n",
      "286/286 [==============================] - 0s 133us/step - loss: 0.6297 - acc: 0.6748\n",
      "Epoch 46/50\n",
      "286/286 [==============================] - 0s 139us/step - loss: 0.6315 - acc: 0.6748\n",
      "Epoch 47/50\n",
      "286/286 [==============================] - 0s 126us/step - loss: 0.6323 - acc: 0.6748\n",
      "Epoch 48/50\n",
      "286/286 [==============================] - 0s 108us/step - loss: 0.6289 - acc: 0.6748\n",
      "Epoch 49/50\n",
      "286/286 [==============================] - 0s 105us/step - loss: 0.6275 - acc: 0.6748\n",
      "Epoch 50/50\n",
      "286/286 [==============================] - 0s 108us/step - loss: 0.6308 - acc: 0.6748\n",
      "143/143 [==============================] - 0s 858us/step\n"
     ]
    }
   ],
   "source": [
    "accuracies=cross_val_score(estimator= model, X=x_train, y= y_train) #n_jobs=-1 means all GPU work parellel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.680652681625\n"
     ]
    }
   ],
   "source": [
    "mean=accuracies.mean()\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0287385231916\n"
     ]
    }
   ],
   "source": [
    "variance= accuracies.std()\n",
    "print(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#has low variance and low bias\n",
    "#has to improve the ANN\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model= Sequential()\n",
    "    model.add(Dense(units=6, kernel_initializer=\"uniform\", activation= \"relu\", input_dim=20))\n",
    "    model.add(Dense(units=6, kernel_initializer=\"uniform\", activation= \"relu\"))\n",
    "    model.add(Dense(units=1, kernel_initializer=\"uniform\", activation= \"sigmoid\"))\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model= KerasClassifier(build_fn= build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters= {'batch_size': [10, 32],'nb_epoch': [100, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_search= GridSearchCV(estimator=model, param_grid = parameters, scoring= 'accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "386/386 [==============================] - 0s 976us/step - loss: 0.6690 - acc: 0.6762\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 0s 1ms/step - loss: 0.6706 - acc: 0.6917\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 0s 1ms/step - loss: 0.6507 - acc: 0.6839\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.6645 - acc: 0.6710\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.7023 - acc: 0.4430\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.6920 - acc: 0.6658\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.6678 - acc: 0.6813\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.6788 - acc: 0.6762\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 1ms/step - loss: 0.6906 - acc: 0.6062\n",
      "Epoch 1/1\n",
      "387/387 [==============================] - 1s 1ms/step - loss: 0.6838 - acc: 0.6796\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.6951 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.6698 - acc: 0.6917\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.6924 - acc: 0.6192\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.6635 - acc: 0.6865\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.6666 - acc: 0.6710\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.7158 - acc: 0.4715\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.6912 - acc: 0.6036\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.6782 - acc: 0.5984\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.6666 - acc: 0.6865\n",
      "Epoch 1/1\n",
      "387/387 [==============================] - 1s 2ms/step - loss: 0.6726 - acc: 0.6925\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.6943 - acc: 0.5959\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.6763 - acc: 0.6917\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.6911 - acc: 0.6554\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.6922 - acc: 0.6658\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.7152 - acc: 0.5751\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 3ms/step - loss: 0.7180 - acc: 0.5233\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 3ms/step - loss: 0.6794 - acc: 0.6891\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 3ms/step - loss: 0.8211 - acc: 0.3705\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 2ms/step - loss: 0.6784 - acc: 0.6865\n",
      "Epoch 1/1\n",
      "387/387 [==============================] - 1s 3ms/step - loss: 0.7127 - acc: 0.4910\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 3ms/step - loss: 0.6799 - acc: 0.6839\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 3ms/step - loss: 0.6793 - acc: 0.6528\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 3ms/step - loss: 0.6843 - acc: 0.5855\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 3ms/step - loss: 0.6728 - acc: 0.6269\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 3ms/step - loss: 0.6680 - acc: 0.6917\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 3ms/step - loss: 0.6653 - acc: 0.6813\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 3ms/step - loss: 0.7600 - acc: 0.4119\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 1s 3ms/step - loss: 0.6732 - acc: 0.6788\n",
      "Epoch 1/1\n",
      "386/386 [==============================] - 2s 5ms/step - loss: 0.6965 - acc: 0.5440\n",
      "Epoch 1/1\n",
      "387/387 [==============================] - 2s 4ms/step - loss: 0.8247 - acc: 0.3230\n",
      "Epoch 1/1\n",
      "429/429 [==============================] - 2s 4ms/step - loss: 0.6728 - acc: 0.6807\n"
     ]
    }
   ],
   "source": [
    "grid_search= grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_parameters= grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_accuracy= grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.687645687646\n"
     ]
    }
   ],
   "source": [
    "print(best_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
